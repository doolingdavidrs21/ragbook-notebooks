{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b720e1c-7fe6-470b-95ea-4b0785188d03",
   "metadata": {},
   "source": [
    "https://learning.oreilly.com/library/view/building-llms-for/9798324731472/index_split_007.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c18bdb-6e9e-497d-a054-5d0de74eefde",
   "metadata": {},
   "source": [
    "# Building LLMs for Production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfd02aa-e46e-4c46-b702-f946af38eabe",
   "metadata": {},
   "source": [
    "All the code notebooks, Google colabs, GitHub repos, research papers, documentation, and other resources are accessible at http://towardsai.net/book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03096c8a-847f-4fe5-9209-d3a80c635966",
   "metadata": {},
   "source": [
    "# Towards AI's AI tutor\n",
    "\n",
    "https://aitutor.towardsai.net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d32ad0e-7e99-4546-9e3a-7c2ad6caaec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "461cdac6-2532-48e3-ad28-3ebe13581c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f35a7cb5-48ce-4119-9060-bc7e45f189d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method create in module openai.resources.completions:\n",
      "\n",
      "create(*, model: \"Union[str, Literal['gpt-3.5-turbo-instruct', 'davinci-002', 'babbage-002']]\", prompt: 'Union[str, List[str], Iterable[int], Iterable[Iterable[int]], None]', best_of: 'Optional[int] | NotGiven' = NOT_GIVEN, echo: 'Optional[bool] | NotGiven' = NOT_GIVEN, frequency_penalty: 'Optional[float] | NotGiven' = NOT_GIVEN, logit_bias: 'Optional[Dict[str, int]] | NotGiven' = NOT_GIVEN, logprobs: 'Optional[int] | NotGiven' = NOT_GIVEN, max_tokens: 'Optional[int] | NotGiven' = NOT_GIVEN, n: 'Optional[int] | NotGiven' = NOT_GIVEN, presence_penalty: 'Optional[float] | NotGiven' = NOT_GIVEN, seed: 'Optional[int] | NotGiven' = NOT_GIVEN, stop: 'Union[Optional[str], List[str], None] | NotGiven' = NOT_GIVEN, stream: 'Optional[Literal[False]] | Literal[True] | NotGiven' = NOT_GIVEN, stream_options: 'Optional[ChatCompletionStreamOptionsParam] | NotGiven' = NOT_GIVEN, suffix: 'Optional[str] | NotGiven' = NOT_GIVEN, temperature: 'Optional[float] | NotGiven' = NOT_GIVEN, top_p: 'Optional[float] | NotGiven' = NOT_GIVEN, user: 'str | NotGiven' = NOT_GIVEN, extra_headers: 'Headers | None' = None, extra_query: 'Query | None' = None, extra_body: 'Body | None' = None, timeout: 'float | httpx.Timeout | None | NotGiven' = NOT_GIVEN) -> 'Completion | Stream[Completion]' method of openai.resources.completions.Completions instance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.completions.create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85a633d2-5cba-41d5-b6c1-5b07301be508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=os.environ['OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21d6e97f-061f-4cd8-87af-84880e469969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method create in module openai.resources.completions:\n",
      "\n",
      "create(*, model: \"Union[str, Literal['gpt-3.5-turbo-instruct', 'davinci-002', 'babbage-002']]\", prompt: 'Union[str, List[str], Iterable[int], Iterable[Iterable[int]], None]', best_of: 'Optional[int] | NotGiven' = NOT_GIVEN, echo: 'Optional[bool] | NotGiven' = NOT_GIVEN, frequency_penalty: 'Optional[float] | NotGiven' = NOT_GIVEN, logit_bias: 'Optional[Dict[str, int]] | NotGiven' = NOT_GIVEN, logprobs: 'Optional[int] | NotGiven' = NOT_GIVEN, max_tokens: 'Optional[int] | NotGiven' = NOT_GIVEN, n: 'Optional[int] | NotGiven' = NOT_GIVEN, presence_penalty: 'Optional[float] | NotGiven' = NOT_GIVEN, seed: 'Optional[int] | NotGiven' = NOT_GIVEN, stop: 'Union[Optional[str], List[str], None] | NotGiven' = NOT_GIVEN, stream: 'Optional[Literal[False]] | Literal[True] | NotGiven' = NOT_GIVEN, stream_options: 'Optional[ChatCompletionStreamOptionsParam] | NotGiven' = NOT_GIVEN, suffix: 'Optional[str] | NotGiven' = NOT_GIVEN, temperature: 'Optional[float] | NotGiven' = NOT_GIVEN, top_p: 'Optional[float] | NotGiven' = NOT_GIVEN, user: 'str | NotGiven' = NOT_GIVEN, extra_headers: 'Headers | None' = None, extra_query: 'Query | None' = None, extra_body: 'Body | None' = None, timeout: 'float | httpx.Timeout | None | NotGiven' = NOT_GIVEN) -> 'Completion | Stream[Completion]' method of openai.resources.completions.Completions instance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.completions.create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deb703d3-5c3e-49ec-9353-bc12b0cb8891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new\n",
    "#from openai import AsyncOpenAI\n",
    "\n",
    "#client = AsyncOpenAI()\n",
    "\n",
    "# English text to translate\n",
    "english_text = \"Hello, how are you?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"Translate the following English text to Fremch: {english_text}\"\"\"}\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "365f26b5-339c-466d-a39b-a23df6e263c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-A0WK8ef7c9vk6kGh5DLkmm5ctagEv', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello, how are you? in French is: \"Bonjour, comment ça va ?\"', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1724687616, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_48196bc67a', usage=CompletionUsage(completion_tokens=17, prompt_tokens=32, total_tokens=49))\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be86f791-2a9e-4df5-b10f-922df199669e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, how are you? in French is: \"Bonjour, comment ça va ?\"\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d214dd8f-55f6-4565-919d-94142b30c6da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
